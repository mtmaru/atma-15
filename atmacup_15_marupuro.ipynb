{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb51b033-6fc4-4a1e-8f02-83a3a4e5d30f",
   "metadata": {},
   "source": [
    "# #15 atmaCup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f62238-84f9-45f0-9f3a-8d6eacf3317b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23589dbc-0e24-418f-8af9-38151531a96e",
   "metadata": {},
   "source": [
    "## セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de263aa-5de5-4ca8-a475-c1fb48ee7bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565757ad-6db9-41cc-9c67-204eac6f2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "anime = pd.read_csv('data/anime.csv', na_values=['Unknown'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca1b7c9-525a-4a81-9388-827561e3ef24",
   "metadata": {},
   "source": [
    "## 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a6fe05-53a7-4aa1-ac3e-a8db58eea3cf",
   "metadata": {},
   "source": [
    "### 共通の前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0dfbee-f04d-43b6-8168-c34cfdd34e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作品名からIPを抽出する。\n",
    "# データ観察の結果から、作品名の先頭4文字でIPを区別できると仮定している。\n",
    "anime['ip'] = (\n",
    "    anime['japanese_name']\n",
    "    .fillna('')\n",
    "    # 作品名の先頭に '劇場版' が付く場合が多いため、あらかじめ '劇場版' を除いておく。\n",
    "    .str.replace('劇場版', '', regex=False)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.normalize('NFKC')\n",
    "    .str.extract(r'^([^\\s]+)')[0]\n",
    "    .str.slice(0, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cedd934-6d31-485c-bbe4-d5fed8868de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_anime = train.merge(anime, how='left', on='anime_id')\n",
    "test_anime = test.merge(anime, how='left', on='anime_id')\n",
    "traintest_anime = pd.concat([train_anime, test_anime], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f0d9e5-edce-4e0d-9e43-ecf12ebec995",
   "metadata": {},
   "source": [
    "### ユーザーとカテゴリーの分散表現の獲得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c127c90-ff39-4cd5-94db-67f52768c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "import scipy as sp\n",
    "\n",
    "# 評価行列 (行：ユーザー、列：カテゴリー、値：評価件数など) を行列分解して\n",
    "# ユーザーとカテゴリー (アニメ作品、ジャンル、……) の分散表現を作る。\n",
    "class UserCategoryNMFTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, traintest_anime, category_column, value_column, func, sep, n_components):\n",
    "        # 評価行列の元になるデータ。\n",
    "        # 学習データ (train.csv) とテストデータ (test.csv) の両方から分散表現を作りたいので、\n",
    "        # 両者を結合したデータを指定する。\n",
    "        self.traintest_anime = traintest_anime\n",
    "        # 評価行列の列を表すカラム。\n",
    "        self.category_column = category_column\n",
    "        # 評価行列の値を表すカラム。\n",
    "        # Noneを指定した場合、評価行列の値として評価件数が使われる。\n",
    "        self.value_column = value_column\n",
    "        # 評価行列の値の集計に用いる関数。\n",
    "        self.func = func\n",
    "        # 複数カテゴリー変数を分割する際に用いるセパレーター。\n",
    "        # 分割せず単カテゴリー変数として扱ったほうが精度が良くなる変数があったことから、\n",
    "        # 分割するか否かを決めるために用いる。\n",
    "        self.sep = sep\n",
    "        # 分散表現の次元数。\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # ユーザー数 x カテゴリー (アニメ作品、ジャンル、……) のスパース行列を作る。\n",
    "        # 行：ユーザー (user_id)。\n",
    "        # 列：カテゴリー (アニメ作品、ジャンル、……)。\n",
    "        # 値：その行のユーザーのその列のカテゴリーに対する評価件数など。\n",
    "        le_user = LabelEncoder()\n",
    "        le_category = LabelEncoder()\n",
    "        count = (\n",
    "            self.traintest_anime\n",
    "            .assign(\n",
    "                category=lambda df: df[self.category_column].str.split(self.sep),\n",
    "                value=lambda df: 1 if self.value_column is None else np.log1p(df[self.value_column])\n",
    "            )\n",
    "            .loc[:, ['user_id', 'category', 'value']]\n",
    "            .explode('category')\n",
    "            .groupby(['user_id', 'category'])['value'].agg(self.func)\n",
    "            .rename('count')\n",
    "            .reset_index()\n",
    "            .assign(\n",
    "                user_id=lambda df: le_user.fit_transform(df['user_id']),\n",
    "                category=lambda df: le_category.fit_transform(df['category'])\n",
    "            )\n",
    "        )\n",
    "        user_category_matrix = csr_matrix((count['count'], (count['user_id'], count['category'])))\n",
    "\n",
    "        # ユーザーの分散表現\n",
    "        # shape: (ユーザー数, n_components)\n",
    "        nmf = NMF(n_components=self.n_components, alpha_W=0.01, max_iter=1000, random_state=0)\n",
    "        user_nmf = nmf.fit_transform(user_category_matrix)\n",
    "        user_nmf = pd.DataFrame(\n",
    "            user_nmf,\n",
    "            index=pd.Index(le_user.classes_, name='user_id'),\n",
    "            columns=[f'user_nmf_{i:02d}' for i in range(self.n_components)]\n",
    "        )\n",
    "        self.user_nmf = user_nmf\n",
    "\n",
    "        # カテゴリーの分散表現\n",
    "        # shape: (カテゴリー数, n_components)\n",
    "        category_nmf = nmf.components_.T\n",
    "        category_nmf = pd.DataFrame(\n",
    "            category_nmf,\n",
    "            index=pd.Index(le_category.classes_, name='category'),\n",
    "            columns=[f'category_nmf_{i:02d}' for i in range(self.n_components)]\n",
    "        )\n",
    "        self.category_nmf = category_nmf\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        target_columns = list(set(['user_id', 'anime_id', self.category_column]))\n",
    "        X_new = (\n",
    "            X[target_columns]\n",
    "            .merge(self.user_nmf, how='left', on='user_id')\n",
    "            # カテゴリーの分散表現を紐づける。\n",
    "            # 該当するカテゴリーが複数ある場合 (ジャンルなど) は、\n",
    "            # 各ジャンルの分散表現の和を紐づける。\n",
    "            .merge(\n",
    "                right=(\n",
    "                    X[target_columns]\n",
    "                    .assign(category=lambda df: df[self.category_column].str.split(self.sep))\n",
    "                    .explode('category')\n",
    "                    .merge(self.category_nmf, how='left', on='category')\n",
    "                    .groupby(['user_id', 'anime_id']).sum(numeric_only=True)\n",
    "                ),\n",
    "                how='left',\n",
    "                on=['user_id', 'anime_id']\n",
    "            )\n",
    "            .drop(columns=target_columns)\n",
    "            .to_numpy()\n",
    "        )\n",
    "\n",
    "        return X_new\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        names = np.concatenate([\n",
    "            self.user_nmf.columns.to_numpy(),\n",
    "            self.category_nmf.columns.to_numpy()\n",
    "        ])\n",
    "\n",
    "        return names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e36d08-1e71-496a-a334-25e3df5c36df",
   "metadata": {},
   "source": [
    "### 評価件数の集計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70449c2-3cc5-4dbd-a930-8af47fd3256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# 各ユーザーが評価した作品数をカウントする。\n",
    "class UserCounter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, traintest_anime):\n",
    "        self.traintest_anime = traintest_anime\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # 各ユーザーの総評価件数\n",
    "        # shape: (ユーザー数, 1)\n",
    "        self.user_count = (\n",
    "            self.traintest_anime\n",
    "            .groupby('user_id').size()\n",
    "            .rename('user')\n",
    "            .to_frame()\n",
    "        )\n",
    "\n",
    "        # 各ユーザーのジャンル別の評価件数\n",
    "        # shape: (ユーザー数, ジャンル数)\n",
    "        self.user_genre_count = (\n",
    "            self.traintest_anime\n",
    "            .assign(genres=lambda df: df['genres'].str.split(', '))\n",
    "            .explode('genres')\n",
    "            .groupby(['user_id', 'genres']).size()\n",
    "            .rename('count')\n",
    "            .reset_index()\n",
    "            .pivot(index='user_id', columns='genres', values='count')\n",
    "            .fillna(0.0)\n",
    "        )\n",
    "        self.user_genre_count.columns = 'genre_' + self.user_genre_count.columns\n",
    "\n",
    "        # 各ユーザーのIP別の評価件数\n",
    "        # shape: (ユーザー数 * IP数, 1)\n",
    "        self.user_ip_count = (\n",
    "            self.traintest_anime\n",
    "            .groupby(['user_id', 'ip']).size()\n",
    "            .rename('count_ip')\n",
    "            .to_frame()\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_new = (\n",
    "            X[['user_id', 'anime_id', 'genres', 'ip']]\n",
    "            .merge(self.user_count, how='left', on='user_id')\n",
    "            .merge(self.user_genre_count, how='left', on='user_id')\n",
    "            .merge(self.user_ip_count, how='left', on=['user_id', 'ip'])\n",
    "            .drop(columns=['user_id', 'anime_id', 'genres', 'ip'])\n",
    "            .to_numpy()\n",
    "        )\n",
    "\n",
    "        return X_new\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        names = np.concatenate([\n",
    "            self.user_count.columns.to_numpy(),\n",
    "            self.user_genre_count.columns.to_numpy(),\n",
    "            self.user_ip_count.columns.to_numpy()\n",
    "        ])\n",
    "\n",
    "        return names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c681c-399f-47aa-8367-dd292bbcd626",
   "metadata": {},
   "source": [
    "### その他の特徴抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cf2593-c0c9-435e-a8e6-2fb32f4aa62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class AssortedTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_new = X.copy()\n",
    "\n",
    "        # カテゴリー変数をカテゴリー型に変換する (LightGBMの categorical_feature に指定する)。\n",
    "        for column in ['type', 'source', 'rating']:\n",
    "            X_new[column] = X_new[column].astype('category')\n",
    "\n",
    "        # airedから放送開始年を抽出する。\n",
    "        X_new['aired'] = X['aired'].str.extract('(\\d{4})').astype(float)\n",
    "\n",
    "        # durationから時間と分を抽出して分に変換する。\n",
    "        X_new['duration'] = (\n",
    "            X['duration'].str.extract(r'(\\d+) hr.').astype(float).fillna(0.0) * 60 +\n",
    "            X['duration'].str.extract(r'(\\d+) min.').astype(float).fillna(0.0)\n",
    "        )\n",
    "\n",
    "        # 見るのを中断した人数と最後まで見た人数の比\n",
    "        X_new['dpr'] = X['dropped'] / X['plan_to_watch']\n",
    "\n",
    "        return X_new\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        names = feature_names_in_ + ['dpr']\n",
    "\n",
    "        return names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136029a5-39ab-4f7f-910d-4494bc325c77",
   "metadata": {},
   "source": [
    "### 特徴抽出のパイプラインの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7547d12f-1058-483e-979d-0e30ecf4059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            f'{transformer_name}' if value_column is None else f'{transformer_name}_{value_column}',\n",
    "            UserCategoryNMFTransformer(\n",
    "                traintest_anime=traintest_anime,\n",
    "                category_column=category_column,\n",
    "                value_column=value_column,\n",
    "                func=func,\n",
    "                sep=sep,\n",
    "                n_components=n_components\n",
    "            ),\n",
    "            list(set(['user_id', 'anime_id', category_column]))\n",
    "        )\n",
    "        for transformer_name, category_column, sep, n_components in [\n",
    "            ('nmf_anime_id_1', 'anime_id', '__dummy_sep__', 50),\n",
    "            ('nmf_anime_id_2', 'anime_id', '__dummy_sep__', 100),\n",
    "            # ('nmf_anime_id_3', 'anime_id', '__dummy_sep__', 75),\n",
    "            ('nmf_genres_1', 'genres', ', ', 5),\n",
    "            ('nmf_genres_2', 'genres', ', ', 10),\n",
    "            # ('nmf_genres_3', 'genres', ', ', 30),\n",
    "            ('nmf_producers_1', 'producers', ', ', 50),\n",
    "            # ('nmf_producers_1', 'producers', '__dummy_sep__', 50),\n",
    "            ('nmf_producers_2', 'producers', ', ', 100),\n",
    "            # ('nmf_producers_2', 'producers', '__dummy_sep__', 100),\n",
    "            # ('nmf_producers_3', 'producers', ', ', 75),\n",
    "            # ('nmf_producers_3', 'producers', '__dummy_sep__', 75),\n",
    "            ('nmf_licensors_1', 'licensors', ', ', 5),\n",
    "            # ('nmf_licensors_1', 'licensors', '__dummy_sep__', 5),\n",
    "            ('nmf_licensors_2', 'licensors', ', ', 10),\n",
    "            # ('nmf_licensors_2', 'licensors', '__dummy_sep__', 10),\n",
    "            # ('nmf_licensors_3', 'licensors', ', ', 30),\n",
    "            # ('nmf_licensors_3', 'licensors', '__dummy_sep__', 30),\n",
    "            ('nmf_studios_1', 'studios', ', ', 20),\n",
    "            # ('nmf_studios_1', 'studios', '__dummy_sep__', 20),\n",
    "            ('nmf_studios_2', 'studios', ', ', 40),\n",
    "            # ('nmf_studios_2', 'studios', '__dummy_sep__', 40),\n",
    "            # ('nmf_studios_3', 'studios', ', ', 30),\n",
    "            # ('nmf_studios_3', 'studios', '__dummy_sep__', 30),\n",
    "            ('nmf_source_1', 'source', '__dummy_sep__', 5),\n",
    "            ('nmf_source_2', 'source', '__dummy_sep__', 10),\n",
    "            # ('nmf_source_3', 'source', '__dummy_sep__', 30),\n",
    "            ('nmf_ip_1', 'ip', '__dummy_sep__', 30),\n",
    "            ('nmf_ip_2', 'ip', '__dummy_sep__', 60),\n",
    "            # ('nmf_ip_3', 'ip', '__dummy_sep__', 45),\n",
    "        ]\n",
    "        for value_column, func in [\n",
    "            (None, 'sum'),\n",
    "            # ('plan_to_watch', 'mean'),\n",
    "            # ('dropped', 'mean')\n",
    "        ]\n",
    "    ] + [\n",
    "        (\n",
    "            'count',\n",
    "            UserCounter(traintest_anime=traintest_anime),\n",
    "            ['user_id', 'anime_id', 'genres', 'ip']\n",
    "        ),\n",
    "        (\n",
    "            'other',\n",
    "            AssortedTransformer(),\n",
    "            [\n",
    "                'type',\n",
    "                'episodes',\n",
    "                'aired',\n",
    "                'source',\n",
    "                'duration',\n",
    "                'rating',\n",
    "                'members',\n",
    "                'watching',\n",
    "                'completed',\n",
    "                'on_hold',\n",
    "                'dropped',\n",
    "                'plan_to_watch'\n",
    "            ]\n",
    "        )\n",
    "    ],\n",
    "    verbose=True\n",
    ")\n",
    "pipeline = pipeline.set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303545b3-0602-4877-a503-4e96ffa39cfa",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d98597-52b3-4f13-b808-012b739d8936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "\n",
    "# テストデータと同じように学習データに存在しないユーザーの評価結果が約23％を占めるようデータを分割する。\n",
    "class UnknownUserKFold:\n",
    "    def __init__(self, n_splits_cv, n_splits_uu):\n",
    "        self.n_splits_cv = n_splits_cv\n",
    "        self.n_splits_uu = n_splits_uu\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        splits_cv = KFold(n_splits=self.n_splits_cv, shuffle=True, random_state=0).split(X)\n",
    "        splits_uu = GroupKFold(n_splits=self.n_splits_uu).split(X, groups=groups)\n",
    "        for fold in range(self.n_splits_cv):\n",
    "            train_index, test_index = next(splits_cv)\n",
    "            _, uu_index = next(splits_uu)\n",
    "            train_index = np.setdiff1d(train_index, uu_index)\n",
    "            test_index = np.union1d(test_index, uu_index)\n",
    "\n",
    "            yield train_index, test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61c0597-3e9d-4ba7-9446-a7820cb159cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pipeline.fit_transform(train_anime, train_anime['score'])\n",
    "y_train = train['score']\n",
    "user_id_train = train['user_id']\n",
    "\n",
    "models = []\n",
    "scores = []\n",
    "cv_details = []\n",
    "kf = UnknownUserKFold(n_splits_cv=5, n_splits_uu=18)\n",
    "for i, (train_index, test_index) in enumerate(kf.split(x_train, groups=user_id_train)):\n",
    "    cv_x_train = x_train.iloc[train_index, :]\n",
    "    cv_y_train = y_train.iloc[train_index]\n",
    "    cv_x_test = x_train.iloc[test_index, :]\n",
    "    cv_y_test = y_train.iloc[test_index]\n",
    "\n",
    "    model = lgb.train(\n",
    "        params={\n",
    "            'objective': 'regression',\n",
    "            'verbose': -1,\n",
    "            'metric': 'rmse',\n",
    "            'learning_rate': 0.01,\n",
    "            'num_leaves': 100,\n",
    "            'feature_fraction': 0.7,\n",
    "            'seed': 127\n",
    "        },\n",
    "        train_set=lgb.Dataset(cv_x_train, label=cv_y_train),\n",
    "        valid_sets=[lgb.Dataset(cv_x_test, label=cv_y_test)],\n",
    "        num_boost_round=20000,\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=500, verbose=True)]\n",
    "    )\n",
    "    models.append(model)\n",
    "    scores.append(model.best_score['valid_0']['rmse'])\n",
    "    print('')\n",
    "\n",
    "    cv_details_ = train_anime.iloc[test_index].copy()\n",
    "    cv_details_['score_pred'] = model.predict(cv_x_test)\n",
    "    cv_details_['score'] = cv_y_test\n",
    "    cv_details.append(cv_details_)\n",
    "\n",
    "cv_details = pd.concat(cv_details, ignore_index=True)\n",
    "print(f'cv: {np.mean(scores):.4f} ± {np.std(scores):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b57391-88e8-4129-a23c-b03469f7b7a8",
   "metadata": {},
   "source": [
    "## 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fcf7bb-ffb0-4804-9480-132ef86fbf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pipeline.transform(test_anime)\n",
    "y_test_pred = np.mean([model.predict(x_test) for model in models], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951b8f69-2c98-435f-9310-4c08ae50587d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(data={'score': y_test_pred})\n",
    "sub.loc[sub['score'] < 1, 'score'] = 1\n",
    "sub.loc[sub['score'] > 10, 'score'] = 10\n",
    "sub.to_csv('submission.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

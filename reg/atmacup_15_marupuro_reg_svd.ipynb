{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb51b033-6fc4-4a1e-8f02-83a3a4e5d30f",
   "metadata": {},
   "source": [
    "# #15 atmaCup 正則化の強さを変えたときの精度 (SVD)\n",
    "\n",
    "比較対象：\n",
    "\n",
    "- SVD (正則化なし)  ← 本notebookはこれ\n",
    "- SVD (正則化あり)\n",
    "- NMF (正則化なし)\n",
    "- NMF (正則化あり)\n",
    "- 行列分解なし"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f62238-84f9-45f0-9f3a-8d6eacf3317b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23589dbc-0e24-418f-8af9-38151531a96e",
   "metadata": {},
   "source": [
    "## セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0de263aa-5de5-4ca8-a475-c1fb48ee7bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565757ad-6db9-41cc-9c67-204eac6f2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "anime = pd.read_csv('data/anime.csv', na_values=['Unknown'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca1b7c9-525a-4a81-9388-827561e3ef24",
   "metadata": {},
   "source": [
    "## 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a6fe05-53a7-4aa1-ac3e-a8db58eea3cf",
   "metadata": {},
   "source": [
    "### 共通の前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cedd934-6d31-485c-bbe4-d5fed8868de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_anime = train.merge(anime, how='left', on='anime_id')\n",
    "test_anime = test.merge(anime, how='left', on='anime_id')\n",
    "traintest_anime = pd.concat([train_anime, test_anime], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f0d9e5-edce-4e0d-9e43-ecf12ebec995",
   "metadata": {},
   "source": [
    "### ユーザーとアニメの分散表現の獲得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b1ba92-931e-4354-89a7-41137bfd8872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "class UserAnimeSVDTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, traintest_anime, n_components):\n",
    "        self.traintest_anime = traintest_anime\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        le_user = LabelEncoder()\n",
    "        le_item = LabelEncoder()\n",
    "        count = (\n",
    "            self.traintest_anime\n",
    "            .assign(\n",
    "                user_id=lambda df: le_user.fit_transform(df['user_id']),\n",
    "                anime_id=lambda df: le_item.fit_transform(df['anime_id']),\n",
    "                count=1\n",
    "            )\n",
    "        )\n",
    "        user_item_matrix = csr_matrix((count['count'], (count['user_id'], count['anime_id'])))\n",
    "\n",
    "        svd = TruncatedSVD(n_components=self.n_components, random_state=0)\n",
    "        user_embedding = svd.fit_transform(user_item_matrix)\n",
    "        user_embedding = pd.DataFrame(\n",
    "            user_embedding,\n",
    "            index=pd.Index(le_user.classes_, name='user_id'),\n",
    "            columns=[f'user_svd_{i:02d}' for i in range(self.n_components)]\n",
    "        )\n",
    "        self.user_embedding = user_embedding\n",
    "\n",
    "        item_embedding = svd.components_.T\n",
    "        item_embedding = pd.DataFrame(\n",
    "            item_embedding,\n",
    "            index=pd.Index(le_item.classes_, name='anime_id'),\n",
    "            columns=[f'item_svd_{i:02d}' for i in range(self.n_components)]\n",
    "        )\n",
    "        self.item_embedding = item_embedding\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        target_columns = ['user_id', 'anime_id']\n",
    "        X_new = (\n",
    "            X[target_columns]\n",
    "            .merge(self.user_embedding, how='left', on='user_id')\n",
    "            .merge(self.item_embedding, how='left', on='anime_id')\n",
    "            .drop(columns=target_columns)\n",
    "            .to_numpy()\n",
    "        )\n",
    "\n",
    "        return X_new\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        names = np.concatenate([\n",
    "            self.user_embedding.columns.to_numpy(),\n",
    "            self.item_embedding.columns.to_numpy()\n",
    "        ])\n",
    "\n",
    "        return names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303545b3-0602-4877-a503-4e96ffa39cfa",
   "metadata": {},
   "source": [
    "## 交差検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d98597-52b3-4f13-b808-012b739d8936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "\n",
    "# テストデータと同じように学習データに存在しないユーザーの評価結果が約23％を占めるようデータを分割する。\n",
    "class UnknownUserKFold:\n",
    "    def __init__(self, n_splits_cv, n_splits_uu):\n",
    "        self.n_splits_cv = n_splits_cv\n",
    "        self.n_splits_uu = n_splits_uu\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        splits_cv = KFold(n_splits=self.n_splits_cv, shuffle=True, random_state=0).split(X)\n",
    "        splits_uu = GroupKFold(n_splits=self.n_splits_uu).split(X, groups=groups)\n",
    "        for fold in range(self.n_splits_cv):\n",
    "            train_index, test_index = next(splits_cv)\n",
    "            _, uu_index = next(splits_uu)\n",
    "            train_index = np.setdiff1d(train_index, uu_index)\n",
    "            test_index = np.union1d(test_index, uu_index)\n",
    "\n",
    "            yield train_index, test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61c0597-3e9d-4ba7-9446-a7820cb159cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_results = []\n",
    "for n_components in [25, 50, 100, 200]:\n",
    "    transformer = UserAnimeSVDTransformer(\n",
    "        traintest_anime=traintest_anime,\n",
    "        n_components=n_components\n",
    "    )\n",
    "    transformer = transformer.set_output(transform='pandas')\n",
    "\n",
    "    x_train = transformer.fit_transform(train_anime)\n",
    "    y_train = train['score']\n",
    "    user_id_train = train['user_id']\n",
    "\n",
    "    kf = UnknownUserKFold(n_splits_cv=5, n_splits_uu=18)\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(x_train, groups=user_id_train)):\n",
    "        cv_x_train = x_train.iloc[train_index, :]\n",
    "        cv_y_train = y_train.iloc[train_index]\n",
    "        cv_x_test = x_train.iloc[test_index, :]\n",
    "        cv_y_test = y_train.iloc[test_index]\n",
    "\n",
    "        model = lgb.train(\n",
    "            params={\n",
    "                'objective': 'regression',\n",
    "                'verbose': -1,\n",
    "                'metric': 'rmse',\n",
    "                'learning_rate': 0.05,\n",
    "                'num_leaves': 100,\n",
    "                'feature_fraction': 0.7,\n",
    "                'seed': 127\n",
    "            },\n",
    "            train_set=lgb.Dataset(cv_x_train, label=cv_y_train),\n",
    "            valid_sets=[lgb.Dataset(cv_x_test, label=cv_y_test)],\n",
    "            num_boost_round=20000,\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]\n",
    "        )\n",
    "\n",
    "        grid_search_result = {}\n",
    "        grid_search_result['n_components'] = n_components\n",
    "        grid_search_result['fold'] = fold\n",
    "        grid_search_result['rmse'] = model.best_score['valid_0']['rmse']\n",
    "        grid_search_results.append(grid_search_result)\n",
    "        print(f\"n_components: {n_components}, fold: {fold}, RMSE: {grid_search_result['rmse']}\")\n",
    "\n",
    "        pd.DataFrame(grid_search_results).to_csv('temp/grid_search_results_svd.csv', index=False, header=True)\n",
    "\n",
    "grid_search_results = pd.DataFrame(grid_search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4460b502-ea32-4a7f-a509-155a9e49bb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e9af8_row0_col0 {\n",
       "  background-color: #5ea0ca;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e9af8_row1_col0 {\n",
       "  background-color: #9fbad9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e9af8_row2_col0 {\n",
       "  background-color: #9ab8d8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e9af8_row3_col0 {\n",
       "  background-color: #4295c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e9af8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e9af8_level0_col0\" class=\"col_heading level0 col0\" >rmse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >n_components</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e9af8_level0_row0\" class=\"row_heading level0 row0\" >25</th>\n",
       "      <td id=\"T_e9af8_row0_col0\" class=\"data row0 col0\" >1.201809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9af8_level0_row1\" class=\"row_heading level0 row1\" >50</th>\n",
       "      <td id=\"T_e9af8_row1_col0\" class=\"data row1 col0\" >1.195729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9af8_level0_row2\" class=\"row_heading level0 row2\" >100</th>\n",
       "      <td id=\"T_e9af8_row2_col0\" class=\"data row2 col0\" >1.196184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9af8_level0_row3\" class=\"row_heading level0 row3\" >200</th>\n",
       "      <td id=\"T_e9af8_row3_col0\" class=\"data row3 col0\" >1.204028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f62ba69c640>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_results = pd.read_csv('temp/grid_search_results_svd.csv')\n",
    "\n",
    "(\n",
    "    grid_search_results\n",
    "    .groupby('n_components')['rmse'].mean()\n",
    "    .to_frame()\n",
    "    .style.background_gradient(vmin=1.18, vmax=1.22)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb51b033-6fc4-4a1e-8f02-83a3a4e5d30f",
   "metadata": {},
   "source": [
    "# #15 atmaCup 正則化の強さを変えたときの精度 (NMF)\n",
    "\n",
    "比較対象：\n",
    "\n",
    "- SVD (正則化なし)\n",
    "- SVD (正則化あり)\n",
    "- NMF (正則化なし)  ← 本notebookはこれ\n",
    "- NMF (正則化あり)  ← 本notebookはこれ\n",
    "- 行列分解なし"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f62238-84f9-45f0-9f3a-8d6eacf3317b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23589dbc-0e24-418f-8af9-38151531a96e",
   "metadata": {},
   "source": [
    "## セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0de263aa-5de5-4ca8-a475-c1fb48ee7bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565757ad-6db9-41cc-9c67-204eac6f2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "anime = pd.read_csv('data/anime.csv', na_values=['Unknown'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca1b7c9-525a-4a81-9388-827561e3ef24",
   "metadata": {},
   "source": [
    "## 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a6fe05-53a7-4aa1-ac3e-a8db58eea3cf",
   "metadata": {},
   "source": [
    "### 共通の前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cedd934-6d31-485c-bbe4-d5fed8868de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_anime = train.merge(anime, how='left', on='anime_id')\n",
    "test_anime = test.merge(anime, how='left', on='anime_id')\n",
    "traintest_anime = pd.concat([train_anime, test_anime], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f0d9e5-edce-4e0d-9e43-ecf12ebec995",
   "metadata": {},
   "source": [
    "### ユーザーとアニメの分散表現の獲得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b1ba92-931e-4354-89a7-41137bfd8872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "class UserAnimeNMFTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, traintest_anime, n_components, alpha_W):\n",
    "        self.traintest_anime = traintest_anime\n",
    "        self.n_components = n_components\n",
    "        self.alpha_W = alpha_W\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        le_user = LabelEncoder()\n",
    "        le_item = LabelEncoder()\n",
    "        count = (\n",
    "            self.traintest_anime\n",
    "            .assign(\n",
    "                user_id=lambda df: le_user.fit_transform(df['user_id']),\n",
    "                anime_id=lambda df: le_item.fit_transform(df['anime_id']),\n",
    "                count=1\n",
    "            )\n",
    "        )\n",
    "        user_item_matrix = csr_matrix((count['count'], (count['user_id'], count['anime_id'])))\n",
    "\n",
    "        nmf = NMF(n_components=self.n_components, alpha_W=self.alpha_W, max_iter=1000, random_state=0)\n",
    "        user_embedding = nmf.fit_transform(user_item_matrix)\n",
    "        user_embedding = pd.DataFrame(\n",
    "            user_embedding,\n",
    "            index=pd.Index(le_user.classes_, name='user_id'),\n",
    "            columns=[f'user_nmf_{i:02d}' for i in range(self.n_components)]\n",
    "        )\n",
    "        self.user_embedding = user_embedding\n",
    "\n",
    "        item_embedding = nmf.components_.T\n",
    "        item_embedding = pd.DataFrame(\n",
    "            item_embedding,\n",
    "            index=pd.Index(le_item.classes_, name='anime_id'),\n",
    "            columns=[f'item_nmf_{i:02d}' for i in range(self.n_components)]\n",
    "        )\n",
    "        self.item_embedding = item_embedding\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        target_columns = ['user_id', 'anime_id']\n",
    "        X_new = (\n",
    "            X[target_columns]\n",
    "            .merge(self.user_embedding, how='left', on='user_id')\n",
    "            .merge(self.item_embedding, how='left', on='anime_id')\n",
    "            .drop(columns=target_columns)\n",
    "            .to_numpy()\n",
    "        )\n",
    "\n",
    "        return X_new\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        names = np.concatenate([\n",
    "            self.user_embedding.columns.to_numpy(),\n",
    "            self.item_embedding.columns.to_numpy()\n",
    "        ])\n",
    "\n",
    "        return names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303545b3-0602-4877-a503-4e96ffa39cfa",
   "metadata": {},
   "source": [
    "## 交差検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d98597-52b3-4f13-b808-012b739d8936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "\n",
    "# テストデータと同じように学習データに存在しないユーザーの評価結果が約23％を占めるようデータを分割する。\n",
    "class UnknownUserKFold:\n",
    "    def __init__(self, n_splits_cv, n_splits_uu):\n",
    "        self.n_splits_cv = n_splits_cv\n",
    "        self.n_splits_uu = n_splits_uu\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        splits_cv = KFold(n_splits=self.n_splits_cv, shuffle=True, random_state=0).split(X)\n",
    "        splits_uu = GroupKFold(n_splits=self.n_splits_uu).split(X, groups=groups)\n",
    "        for fold in range(self.n_splits_cv):\n",
    "            train_index, test_index = next(splits_cv)\n",
    "            _, uu_index = next(splits_uu)\n",
    "            train_index = np.setdiff1d(train_index, uu_index)\n",
    "            test_index = np.union1d(test_index, uu_index)\n",
    "\n",
    "            yield train_index, test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61c0597-3e9d-4ba7-9446-a7820cb159cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_results = []\n",
    "for n_components in [25, 50, 100, 200]:\n",
    "    for alpha_W in [0, 0.1, 0.03, 0.01, 0.003, 0.001, 0.0003]:\n",
    "        transformer = UserAnimeNMFTransformer(\n",
    "            traintest_anime=traintest_anime,\n",
    "            n_components=n_components,\n",
    "            alpha_W=alpha_W\n",
    "        )\n",
    "        transformer = transformer.set_output(transform='pandas')\n",
    "\n",
    "        x_train = transformer.fit_transform(train_anime)\n",
    "        y_train = train['score']\n",
    "        user_id_train = train['user_id']\n",
    "\n",
    "        kf = UnknownUserKFold(n_splits_cv=5, n_splits_uu=18)\n",
    "        for fold, (train_index, test_index) in enumerate(kf.split(x_train, groups=user_id_train)):\n",
    "            cv_x_train = x_train.iloc[train_index, :]\n",
    "            cv_y_train = y_train.iloc[train_index]\n",
    "            cv_x_test = x_train.iloc[test_index, :]\n",
    "            cv_y_test = y_train.iloc[test_index]\n",
    "\n",
    "            model = lgb.train(\n",
    "                params={\n",
    "                    'objective': 'regression',\n",
    "                    'verbose': -1,\n",
    "                    'metric': 'rmse',\n",
    "                    'learning_rate': 0.05,\n",
    "                    'num_leaves': 100,\n",
    "                    'feature_fraction': 0.7,\n",
    "                    'seed': 127\n",
    "                },\n",
    "                train_set=lgb.Dataset(cv_x_train, label=cv_y_train),\n",
    "                valid_sets=[lgb.Dataset(cv_x_test, label=cv_y_test)],\n",
    "                num_boost_round=20000,\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]\n",
    "            )\n",
    "\n",
    "            grid_search_result = {}\n",
    "            grid_search_result['n_components'] = n_components\n",
    "            grid_search_result['alpha_W'] = alpha_W\n",
    "            grid_search_result['fold'] = fold\n",
    "            grid_search_result['rmse'] = model.best_score['valid_0']['rmse']\n",
    "            grid_search_results.append(grid_search_result)\n",
    "            print(f\"n_components: {n_components}, alpha_W: {alpha_W}, fold: {fold}, RMSE: {grid_search_result['rmse']}\")\n",
    "\n",
    "            pd.DataFrame(grid_search_results).to_csv('temp/grid_search_results_nmf_temp.csv', index=False, header=True)\n",
    "\n",
    "grid_search_results = pd.DataFrame(grid_search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8df4ce96-2557-4caa-8064-4515b100e059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a1285_row0_col0 {\n",
       "  background-color: #0570b0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1285_row0_col1 {\n",
       "  background-color: #0872b1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1285_row0_col2 {\n",
       "  background-color: #056faf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1285_row0_col3 {\n",
       "  background-color: #2484ba;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1285_row0_col4 {\n",
       "  background-color: #3991c1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1285_row0_col5, #T_a1285_row0_col6, #T_a1285_row1_col5, #T_a1285_row1_col6, #T_a1285_row2_col5, #T_a1285_row2_col6, #T_a1285_row3_col5, #T_a1285_row3_col6 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1285_row1_col0, #T_a1285_row2_col1 {\n",
       "  background-color: #509ac6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1285_row1_col1 {\n",
       "  background-color: #2c89bd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1285_row1_col2 {\n",
       "  background-color: #1c7fb8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1285_row1_col3 {\n",
       "  background-color: #1278b4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1285_row1_col4 {\n",
       "  background-color: #81aed2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1285_row2_col0 {\n",
       "  background-color: #0d75b3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1285_row2_col2 {\n",
       "  background-color: #4697c4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1285_row2_col3 {\n",
       "  background-color: #7bacd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1285_row2_col4 {\n",
       "  background-color: #73a9cf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1285_row3_col0 {\n",
       "  background-color: #0566a0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1285_row3_col1 {\n",
       "  background-color: #2383ba;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1285_row3_col2 {\n",
       "  background-color: #4e9ac6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1285_row3_col3 {\n",
       "  background-color: #3b92c1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1285_row3_col4 {\n",
       "  background-color: #a5bddb;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a1285\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >alpha_W</th>\n",
       "      <th id=\"T_a1285_level0_col0\" class=\"col_heading level0 col0\" >0.000000</th>\n",
       "      <th id=\"T_a1285_level0_col1\" class=\"col_heading level0 col1\" >0.000300</th>\n",
       "      <th id=\"T_a1285_level0_col2\" class=\"col_heading level0 col2\" >0.001000</th>\n",
       "      <th id=\"T_a1285_level0_col3\" class=\"col_heading level0 col3\" >0.003000</th>\n",
       "      <th id=\"T_a1285_level0_col4\" class=\"col_heading level0 col4\" >0.010000</th>\n",
       "      <th id=\"T_a1285_level0_col5\" class=\"col_heading level0 col5\" >0.030000</th>\n",
       "      <th id=\"T_a1285_level0_col6\" class=\"col_heading level0 col6\" >0.100000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >n_components</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a1285_level0_row0\" class=\"row_heading level0 row0\" >25</th>\n",
       "      <td id=\"T_a1285_row0_col0\" class=\"data row0 col0\" >1.209895</td>\n",
       "      <td id=\"T_a1285_row0_col1\" class=\"data row0 col1\" >1.209583</td>\n",
       "      <td id=\"T_a1285_row0_col2\" class=\"data row0 col2\" >1.210081</td>\n",
       "      <td id=\"T_a1285_row0_col3\" class=\"data row0 col3\" >1.206764</td>\n",
       "      <td id=\"T_a1285_row0_col4\" class=\"data row0 col4\" >1.204748</td>\n",
       "      <td id=\"T_a1285_row0_col5\" class=\"data row0 col5\" >1.232027</td>\n",
       "      <td id=\"T_a1285_row0_col6\" class=\"data row0 col6\" >1.451748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1285_level0_row1\" class=\"row_heading level0 row1\" >50</th>\n",
       "      <td id=\"T_a1285_row1_col0\" class=\"data row1 col0\" >1.202833</td>\n",
       "      <td id=\"T_a1285_row1_col1\" class=\"data row1 col1\" >1.206084</td>\n",
       "      <td id=\"T_a1285_row1_col2\" class=\"data row1 col2\" >1.207553</td>\n",
       "      <td id=\"T_a1285_row1_col3\" class=\"data row1 col3\" >1.208667</td>\n",
       "      <td id=\"T_a1285_row1_col4\" class=\"data row1 col4\" >1.198688</td>\n",
       "      <td id=\"T_a1285_row1_col5\" class=\"data row1 col5\" >1.232849</td>\n",
       "      <td id=\"T_a1285_row1_col6\" class=\"data row1 col6\" >1.426319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1285_level0_row2\" class=\"row_heading level0 row2\" >100</th>\n",
       "      <td id=\"T_a1285_row2_col0\" class=\"data row2 col0\" >1.209216</td>\n",
       "      <td id=\"T_a1285_row2_col1\" class=\"data row2 col1\" >1.202897</td>\n",
       "      <td id=\"T_a1285_row2_col2\" class=\"data row2 col2\" >1.203727</td>\n",
       "      <td id=\"T_a1285_row2_col3\" class=\"data row2 col3\" >1.199313</td>\n",
       "      <td id=\"T_a1285_row2_col4\" class=\"data row2 col4\" >1.200120</td>\n",
       "      <td id=\"T_a1285_row2_col5\" class=\"data row2 col5\" >1.225843</td>\n",
       "      <td id=\"T_a1285_row2_col6\" class=\"data row2 col6\" >1.374419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1285_level0_row3\" class=\"row_heading level0 row3\" >200</th>\n",
       "      <td id=\"T_a1285_row3_col0\" class=\"data row3 col0\" >1.212248</td>\n",
       "      <td id=\"T_a1285_row3_col1\" class=\"data row3 col1\" >1.206905</td>\n",
       "      <td id=\"T_a1285_row3_col2\" class=\"data row3 col2\" >1.202992</td>\n",
       "      <td id=\"T_a1285_row3_col3\" class=\"data row3 col3\" >1.204649</td>\n",
       "      <td id=\"T_a1285_row3_col4\" class=\"data row3 col4\" >1.195074</td>\n",
       "      <td id=\"T_a1285_row3_col5\" class=\"data row3 col5\" >1.223843</td>\n",
       "      <td id=\"T_a1285_row3_col6\" class=\"data row3 col6\" >1.357148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa8511cfe80>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_results = pd.read_csv('temp/grid_search_results_nmf.csv')\n",
    "\n",
    "(\n",
    "    grid_search_results\n",
    "    .groupby(['n_components', 'alpha_W'])['rmse'].mean()\n",
    "    .unstack()\n",
    "    .style.background_gradient(vmin=1.18, vmax=1.22)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
